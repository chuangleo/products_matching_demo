import csv
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import random
from urllib.parse import quote
import re
import warnings
import logging
import os

# åœ¨æ–‡ä»¶é–‹é ­æ·»åŠ é€™äº›è¡Œä¾†æŠ‘åˆ¶æ‰€æœ‰è­¦å‘Šå’Œæ—¥èªŒ
warnings.filterwarnings("ignore")
logging.getLogger('selenium').setLevel(logging.CRITICAL)
logging.getLogger('urllib3').setLevel(logging.CRITICAL)

# æŠ‘åˆ¶ Chrome ç›¸é—œçš„éŒ¯èª¤è¨Šæ¯
os.environ['WDM_LOG_LEVEL'] = '0'
os.environ['WDM_PRINT_FIRST_LINE'] = 'False'

def fetch_products_for_momo(keyword, max_products=50, progress_callback=None, cancel_check=None):
    """
    ä½¿ç”¨ Selenium å¾ momo è³¼ç‰©ç¶²æŠ“å–å•†å“è³‡è¨Š
    
    Args:
        keyword (str): æœå°‹é—œéµå­—
        max_products (int): æœ€å¤§æŠ“å–å•†å“æ•¸é‡
        progress_callback (function): é€²åº¦å›èª¿å‡½å¼ï¼Œæ¥æ”¶ (current, total, message) åƒæ•¸
        cancel_check (function): å–æ¶ˆæª¢æŸ¥å‡½å¼ï¼Œè¿”å› True è¡¨ç¤ºéœ€è¦å–æ¶ˆ
    
    Returns:
        list: å•†å“è³‡è¨Šåˆ—è¡¨ï¼Œæ¯å€‹å•†å“åŒ…å« id, title, price, image_url, url, platform, sku
    """
    
    products = []
    product_id = 1  # é †åºç·¨è™Ÿ
    driver = None
    page = 1  # ç•¶å‰é æ•¸
    seen_skus = set()  # è¿½è¹¤å·²ç¶“æ”¶é›†çš„ SKUï¼Œé¿å…é‡è¤‡
    consecutive_empty_pages = 0  # é€£çºŒç©ºç™½é è¨ˆæ•¸å™¨
    
    try:
        # è¨­å®š Chrome é¸é …
        chrome_options = Options()
        chrome_options.add_argument('--headless=new')  # ä½¿ç”¨æ–°çš„ç„¡é ­æ¨¡å¼
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-software-rasterizer')
        chrome_options.add_argument('--remote-debugging-port=9222')
        chrome_options.add_argument('--disable-setuid-sandbox')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36')
        
        # ç¦ç”¨åœ–ç‰‡è¼‰å…¥ä»¥æé«˜é€Ÿåº¦ï¼ˆå·²è¨»è§£ï¼Œé¡¯ç¤ºåœ–ç‰‡ï¼‰
        prefs = {
            # "profile.managed_default_content_settings.images": 2,  # å·²è¨»è§£ï¼Œå…è¨±è¼‰å…¥åœ–ç‰‡
            "profile.default_content_setting_values.notifications": 2
        }
        chrome_options.add_experimental_option("prefs", prefs)
        chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
        
        # è¨­å®šé é¢è¼‰å…¥ç­–ç•¥ï¼ˆä¸ç­‰å¾…å…¨éƒ¨è³‡æºï¼‰
        chrome_options.page_load_strategy = 'eager'
        
        # åˆå§‹åŒ– WebDriverï¼ˆè‡ªå‹•ä¸‹è¼‰ä¸¦ä½¿ç”¨ ChromeDriverï¼‰
        try:
            # ä½¿ç”¨ webdriver_manager è‡ªå‹•ç®¡ç† chromedriver
            chromedriver_path = ChromeDriverManager().install()
            
            # è¨­å®šåŸ·è¡Œæ¬Šé™ï¼ˆWindows ä¸Šé€šå¸¸ä¸éœ€è¦ï¼Œä½†åŠ ä¸Šç¢ºä¿æ²’å•é¡Œï¼‰
            service = Service(chromedriver_path)
            driver = webdriver.Chrome(service=service, options=chrome_options)
        except Exception as driver_error:
            print(f"âš ï¸ ChromeDriver åˆå§‹åŒ–å¤±æ•—: {driver_error}")
            print("ğŸ’¡ å˜—è©¦ä½¿ç”¨ç³»çµ± PATH ä¸­çš„ ChromeDriver...")
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ç³»çµ±ä¸­çš„ chromedriver
            driver = webdriver.Chrome(options=chrome_options)
        
        driver.set_page_load_timeout(60)  # å¢åŠ åˆ° 60 ç§’
        print(f"æ­£åœ¨æœå°‹ momo: {keyword}")
        
        # ğŸ“Š å›å ±åˆå§‹é€²åº¦
        if progress_callback:
            progress_callback(0, max_products, f'ğŸ” æ­£åœ¨æœå°‹ MOMO: {keyword}')
        
        # ç­‰å¾…é é¢è¼‰å…¥
        wait = WebDriverWait(driver, 30)  # å¢åŠ åˆ° 30 ç§’
        
        # å¤šé æŠ“å–å¾ªç’°
        while len(products) < max_products:
            # æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
            if cancel_check and cancel_check():
                print("âŒ MOMO æœå°‹å·²è¢«å–æ¶ˆ")
                break
            
            # å»ºæ§‹æœå°‹ URLï¼ˆåŒ…å«é æ•¸ï¼‰
            encoded_keyword = quote(keyword)
            search_url = f"https://www.momoshop.com.tw/search/searchShop.jsp?keyword={encoded_keyword}&searchType=1&cateLevel=0&ent=k&sortType=1&curPage={page}"
            
            print(f"æ­£åœ¨æŠ“å–ç¬¬ {page} é ...")
            
            # ğŸ“Š å›å ±é é¢è¼‰å…¥é€²åº¦
            if progress_callback:
                progress_callback(len(products), max_products, f'(å·²æ”¶é›† {len(products)}/{max_products} ç­†)')
            
            # è¼‰å…¥é é¢ï¼ˆåŠ å…¥é‡è©¦æ©Ÿåˆ¶ï¼‰
            retry_count = 0
            max_retries = 3
            page_loaded = False
            
            while retry_count < max_retries and not page_loaded:
                try:
                    # æª¢æŸ¥ driver æœƒè©±æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                    try:
                        _ = driver.current_url
                    except Exception as session_error:
                        print(f"âš ï¸ WebDriver æœƒè©±å¤±æ•ˆï¼Œé‡æ–°åˆå§‹åŒ–ç€è¦½å™¨...")
                        try:
                            driver.quit()
                        except:
                            pass
                        driver = webdriver.Chrome(service=service, options=chrome_options)
                        driver.set_page_load_timeout(60)
                        wait = WebDriverWait(driver, 30)
                    
                    driver.get(search_url)
                    time.sleep(2)  # ç­‰å¾…é é¢è¼‰å…¥
                    page_loaded = True
                except Exception as e:
                    retry_count += 1
                    error_msg = str(e)
                    if "invalid session id" in error_msg:
                        print(f"âš ï¸ æœƒè©±å¤±æ•ˆ (å˜—è©¦ {retry_count}/{max_retries})ï¼Œé‡æ–°åˆå§‹åŒ–ç€è¦½å™¨...")
                        try:
                            driver.quit()
                        except:
                            pass
                        # é‡æ–°å‰µå»º driver
                        driver = webdriver.Chrome(service=service, options=chrome_options)
                        driver.set_page_load_timeout(60)
                        wait = WebDriverWait(driver, 30)
                        time.sleep(2)
                    elif "ERR_INTERNET_DISCONNECTED" in error_msg or "ERR_CONNECTION" in error_msg:
                        print(f"âš ï¸ ç¶²è·¯é€£ç·šéŒ¯èª¤ (å˜—è©¦ {retry_count}/{max_retries})ï¼Œç­‰å¾… 3 ç§’å¾Œé‡è©¦...")
                        time.sleep(3)
                    else:
                        print(f"âŒ é é¢è¼‰å…¥éŒ¯èª¤: {e}")
                        break
            
            if not page_loaded:
                print(f"âŒ ç¬¬ {page} é è¼‰å…¥å¤±æ•—ï¼Œå·²é‡è©¦ {max_retries} æ¬¡ï¼Œåœæ­¢æŠ“å–")
                break
            
            try:
                # ğŸ” æª¢æŸ¥è¦–çª—æ˜¯å¦é‚„å­˜åœ¨
                try:
                    _ = driver.current_url
                except Exception as window_error:
                    print(f"âŒ Chrome è¦–çª—å·²é—œé–‰æˆ–å¤±å»é€£ç·š: {window_error}")
                    break
                
                # ğŸ†• å…ˆæª¢æŸ¥ç¶²é é¡¯ç¤ºçš„ç¸½å•†å“æ•¸
                try:
                    total_count_element = driver.find_element(By.CSS_SELECTOR, "span.total-txt b")
                    total_count_text = total_count_element.text
                    total_available = int(total_count_text)
                    print(f"ğŸ“Š ç¶²é é¡¯ç¤ºå…±æœ‰ {total_available} ä»¶å•†å“")
                    
                    # å¦‚æœç¸½å•†å“æ•¸ç‚º 0ï¼Œç›´æ¥åœæ­¢
                    if total_available == 0:
                        print("âŒ æœå°‹çµæœç‚º 0 ä»¶å•†å“ï¼Œåœæ­¢æŠ“å–")
                        break
                    
                    # å¦‚æœç¸½å•†å“æ•¸å°‘æ–¼ç›®æ¨™æ•¸é‡ï¼Œèª¿æ•´ç›®æ¨™
                    if total_available < max_products:
                        print(f"âš ï¸ ç¸½å•†å“æ•¸ ({total_available}) å°‘æ–¼ç›®æ¨™æ•¸é‡ ({max_products})ï¼Œå°‡æŠ“å–æ‰€æœ‰å•†å“")
                        # ä¸ä¿®æ”¹ max_productsï¼Œè€Œæ˜¯åœ¨æŠ“å®Œæ‰€æœ‰å•†å“å¾Œè‡ªå‹•åœæ­¢
                    
                    # å¦‚æœå·²ç¶“æŠ“å¤ äº†ï¼Œåœæ­¢
                    if len(products) >= total_available:
                        print(f"âœ… å·²æ”¶é›†å…¨éƒ¨ {total_available} ä»¶å•†å“ï¼Œåœæ­¢æŠ“å–")
                        break
                        
                except (NoSuchElementException, ValueError) as e:
                    print(f"âš ï¸ ç„¡æ³•è®€å–å•†å“ç¸½æ•¸ï¼Œç¹¼çºŒä½¿ç”¨èˆŠé‚è¼¯: {e}")
                
                # å˜—è©¦æŸ¥æ‰¾å•†å“å…ƒç´ ï¼ˆä½¿ç”¨æ›´ç²¾ç¢ºçš„é¸æ“‡å™¨ï¼‰
                selectors_to_try = [
                    "li.listAreaLi",                    # æœ€å¸¸è¦‹çš„å•†å“åˆ—è¡¨é …
                    ".listAreaUl li.listAreaLi",        # å®Œæ•´è·¯å¾‘
                    "li.goodsItemLi",                   # å•†å“é …ç›®
                    ".prdListArea .goodsItemLi",        # å•†å“åˆ—è¡¨å€åŸŸçš„å•†å“é …ç›®
                    "li[data-gtm]",                     # æœ‰ GTM è¿½è¹¤å±¬æ€§çš„å•†å“
                    ".goodsItemLi",                     # å•†å“é …ç›®é¡åˆ¥
                    # ç§»é™¤å¤ªå¯¬æ³›çš„é¸æ“‡å™¨ï¼š".searchPrdListArea li", ".searchPrdList li"
                ]
                
                product_elements = []
                used_selector = None
                for selector in selectors_to_try:
                    try:
                        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))
                        temp_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                        if temp_elements:
                            product_elements = temp_elements
                            used_selector = selector
                            break
                    except TimeoutException:
                        continue
                
                if not product_elements:
                    print("ç„¡æ³•æ‰¾åˆ°å•†å“å…ƒç´ ï¼Œå¯èƒ½é é¢çµæ§‹å·²æ”¹è®Šæˆ–å·²åˆ°é”æœ€å¾Œä¸€é ")
                    break
                
                print(f"ä½¿ç”¨é¸æ“‡å™¨ '{used_selector}' æ‰¾åˆ° {len(product_elements)} å€‹å…ƒç´ ")
                
            except TimeoutException:
                print(f"ç¬¬ {page} é è¼‰å…¥è¶…æ™‚ï¼Œåœæ­¢æŠ“å–")
                break
            
            print(f"é–‹å§‹è§£æ {len(product_elements)} å€‹å•†å“")
            page_products_count = 0
            consecutive_duplicates = 0  # é€£çºŒé‡è¤‡å•†å“è¨ˆæ•¸å™¨
            max_consecutive_duplicates = 10  # é€£çºŒ 10 å€‹é‡è¤‡å°±åœæ­¢è©²é 
            skipped_empty_elements = 0  # è¨˜éŒ„è·³éçš„ç©ºå…ƒç´ æ•¸é‡
            
            # è§£ææ¯å€‹å•†å“
            for i, element in enumerate(product_elements):
                # æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                if cancel_check and cancel_check():
                    print("âŒ MOMO æœå°‹å·²è¢«å–æ¶ˆ")
                    break
                
                try:
                    # å¦‚æœå·²ç¶“ç²å¾—è¶³å¤ çš„å•†å“ï¼Œå°±åœæ­¢
                    if len(products) >= max_products:
                        break
                    
                    # ğŸ” å¿«é€Ÿæª¢æŸ¥ï¼šé€™å€‹å…ƒç´ æ˜¯å¦çœŸçš„åŒ…å«å•†å“è³‡è¨Š
                    # æª¢æŸ¥æ˜¯å¦æœ‰æ¨™é¡Œæˆ–åƒ¹æ ¼ç›¸é—œçš„æ–‡å­—
                    element_text = element.text.strip()
                    if not element_text or len(element_text) < 5:
                        # print(f"å…ƒç´  {i+1} æ²’æœ‰æ–‡å­—å…§å®¹ï¼Œè·³é")
                        skipped_empty_elements += 1
                        continue
                    
                    # æå–å•†å“æ¨™é¡Œ
                    title = ""
                    title_selectors = [
                        "h3.prdName",
                        ".prdNameTitle h3.prdName",
                        ".prdName",
                        "h3",
                        "a[title]",
                        "img[alt]",
                        ".goodsName",
                        ".goodsInfo h3",
                        "a"
                    ]
                    
                    for selector in title_selectors:
                        try:
                            title_elem = element.find_element(By.CSS_SELECTOR, selector)
                            if selector == "img[alt]":
                                title = title_elem.get_attribute("alt").strip()
                            elif selector == "a[title]":
                                title = title_elem.get_attribute("title").strip()
                            else:
                                title = title_elem.text.strip()
                            
                            if title and len(title) > 5:  # ç¢ºä¿æ¨™é¡Œæœ‰è¶³å¤ é•·åº¦
                                break
                        except NoSuchElementException:
                            continue
                    
                    # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™é¡Œï¼Œè·³éé€™å€‹å•†å“
                    if not title:
                        continue
                    
                    # æå–åƒ¹æ ¼ï¼ˆå…ˆç”¨å¤šç¨®é¸æ“‡å™¨ï¼Œè‹¥å¤±æ•—å‰‡ç”¨æ•´å€‹å…ƒç´ çš„æ–‡å­—åšå›é€€ï¼‰
                    price = 0
                    price_selectors = [
                        ".money .price b",
                        ".price b",
                        ".money b",
                        ".price",
                        ".money",
                        ".cost",
                        "b",
                        "strong",
                        ".goodsPrice",
                        ".priceInfo",
                        ".prodPrice",
                        ".prdPrice"
                    ]

                    for selector in price_selectors:
                        try:
                            price_elements = element.find_elements(By.CSS_SELECTOR, selector)
                            for price_elem in price_elements:
                                price_text = price_elem.text
                                if price_text and any(c.isdigit() for c in price_text):
                                    # æå–æ•¸å­—
                                    numbers = re.findall(r'\d+', price_text.replace(',', ''))
                                    if numbers:
                                        # å–æœ€å¤§çš„æ•¸å­—ä½œç‚ºåƒ¹æ ¼ï¼ˆé¿å…å–åˆ°æŠ˜æ‰£ç™¾åˆ†æ¯”ç­‰å°æ•¸å­—ï¼‰
                                        potential_prices = [int(num) for num in numbers if int(num) > 10]
                                        if potential_prices:
                                            price = max(potential_prices)
                                            break
                            if price > 0:
                                break
                        except NoSuchElementException:
                            continue

                    # å›é€€ç­–ç•¥ï¼šç”¨æ•´å€‹å…ƒç´ çš„æ–‡æœ¬æŠ“å–æ•¸å­—ï¼ˆå¦‚æœå…ˆå‰æ²’æŠ“åˆ°åƒ¹æ ¼ï¼‰
                    if price <= 0:
                        try:
                            full_text = element.text
                            numbers = re.findall(r'\d+', full_text.replace(',', ''))
                            if numbers:
                                potential_prices = [int(num) for num in numbers if int(num) > 10]
                                if potential_prices:
                                    price = max(potential_prices)
                        except Exception:
                            price = 0

                    # å¦‚æœé‚„æ²’æœ‰æ‰¾åˆ°åƒ¹æ ¼ï¼Œå°±è·³éé€™å€‹å•†å“
                    if price <= 0:
                        continue
                    
                    # æå–å•†å“é€£çµ
                    url = ""
                    try:
                        link_elem = element.find_element(By.CSS_SELECTOR, "a.goods-img-url")
                        url = link_elem.get_attribute("href")
                        if not url.startswith("http"):
                            url = "https://www.momoshop.com.tw" + url
                    except NoSuchElementException:
                        # å˜—è©¦æ‰¾å…¶ä»–å¯èƒ½çš„é€£çµé¸æ“‡å™¨
                        try:
                            link_elem = element.find_element(By.CSS_SELECTOR, "a[href*='/goods/']")
                            url = link_elem.get_attribute("href")
                            if not url.startswith("http"):
                                url = "https://www.momoshop.com.tw" + url
                        except NoSuchElementException:
                            # å˜—è©¦æ‰¾ä»»ä½•é€£çµ
                            try:
                                link_elem = element.find_element(By.CSS_SELECTOR, "a[href]")
                                url = link_elem.get_attribute("href")
                                if url and not url.startswith("http"):
                                    url = "https://www.momoshop.com.tw" + url
                            except NoSuchElementException:
                                url = ""
                    
                    # å˜—è©¦å¾éš±è— input å–å¾—å•†å“ id ä½œç‚º skuï¼ˆmomo çš„ list ä¸­å¸¸è¦‹ï¼‰
                    sku = ""
                    try:
                        input_elem = element.find_element(By.CSS_SELECTOR, "input#viewProdId")
                        sku_val = input_elem.get_attribute("value")
                        if sku_val:
                            sku = sku_val
                    except NoSuchElementException:
                        sku = ""

                    # è‹¥ä»ç„¡ skuï¼Œå˜—è©¦å¾ url æå– i_code æˆ–æœ€å¾Œä¸€æ®µ
                    if not sku and url:
                        match = re.search(r'i_code=(\d+)', url)
                        if match:
                            sku = match.group(1)
                        else:
                            url_parts = url.rstrip('/').split('/')
                            if url_parts:
                                last_part = url_parts[-1]
                                if '?' in last_part:
                                    last_part = last_part.split('?')[0]
                                if '.' in last_part:
                                    last_part = last_part.split('.')[0]
                                sku = last_part
                    # å¦‚æœæœ‰ sku ä½†æ²’æœ‰ urlï¼Œå¯ä»¥ç”¨ momo çš„å•†å“é æ¨£å¼çµ„æˆ url
                    if not url and sku:
                        url = f"https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code={sku}"
                    
                    # æå–å•†å“åœ–ç‰‡ - ä½¿ç”¨å¤šé‡ç­–ç•¥æé«˜æˆåŠŸç‡
                    image_url = ""
                    
                    # åœ–ç‰‡é¸æ“‡å™¨åˆ—è¡¨ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰
                    img_selectors = [
                        "img.goods-img",  # 2025 æœ€æ–°çµæ§‹
                        "img.prdImg",
                        "img.goodsImg",
                        "a.goods-img-url img",
                        "div.goods-img img",
                        "img[src*='goodsImg']",
                        "img[src*='momoshop']",
                        "img[data-original*='goodsImg']",
                        "img[alt]",  # ä»»ä½•æœ‰ alt å±¬æ€§çš„åœ–ç‰‡
                    ]
                    
                    for selector in img_selectors:
                        try:
                            img_elem = element.find_element(By.CSS_SELECTOR, selector)
                            # å˜—è©¦å¤šå€‹å±¬æ€§ä¾†ç²å–åœ–ç‰‡ç¶²å€
                            image_url = (img_elem.get_attribute("src") or 
                                       img_elem.get_attribute("data-src") or 
                                       img_elem.get_attribute("data-original") or
                                       img_elem.get_attribute("data-lazy") or
                                       img_elem.get_attribute("data-image"))
                            
                            # éæ¿¾æ‰ä¸æ˜¯å•†å“åœ–ç‰‡çš„ URL
                            if image_url and image_url != "" and image_url != "about:blank":
                                # æ’é™¤å®˜æ–¹æ¨™ç±¤ã€placeholderã€icon ç­‰éå•†å“åœ–ç‰‡
                                exclude_patterns = [
                                    "placeholder",
                                    "offical_tag",  # å®˜æ–¹æ¨™ç±¤
                                    "official_tag",
                                    "ec-images",    # æ´»å‹•æ¨™ç±¤åœ–ç‰‡
                                    "icon",
                                    "logo",
                                    "banner",
                                    "_tag_",
                                    "tag.png",
                                    "tag.jpg",
                                    "data:image",  # Base64 åœ–ç‰‡
                                ]
                                
                                # æª¢æŸ¥æ˜¯å¦åŒ…å«æ’é™¤çš„æ¨¡å¼
                                if any(pattern in image_url.lower() for pattern in exclude_patterns):
                                    continue  # è·³éé€™å€‹åœ–ç‰‡ï¼Œå˜—è©¦ä¸‹ä¸€å€‹
                                
                                # è™•ç†ç›¸å°è·¯å¾‘å’Œå”è­°ç›¸å°è·¯å¾‘
                                if image_url.startswith("//"):
                                    image_url = "https:" + image_url
                                elif image_url.startswith("/"):
                                    image_url = "https://www.momoshop.com.tw" + image_url
                                elif not image_url.startswith("http"):
                                    # å¦‚æœæ˜¯ç›¸å°è·¯å¾‘ä½†ä¸ä»¥ / é–‹é ­
                                    if "momoshop" not in image_url:
                                        image_url = "https://img.momoshop.com.tw/" + image_url
                                    else:
                                        image_url = "https://" + image_url
                                
                                # ç¢ºä¿åœ–ç‰‡ URL ä½¿ç”¨é©ç•¶çš„å°ºå¯¸åƒæ•¸
                                # MOMO åœ–ç‰‡é€šå¸¸æ ¼å¼ç‚º: https://imgX.momoshop.com.tw/...?t=timestamp
                                if "momoshop.com.tw" in image_url and "?" not in image_url:
                                    # æ·»åŠ æ™‚é–“æˆ³åƒæ•¸é¿å…å¿«å–å•é¡Œ
                                    import datetime
                                    timestamp = datetime.datetime.now().strftime("%Y%m%d")
                                    image_url = f"{image_url}?t={timestamp}"
                                
                                break  # æ‰¾åˆ°æœ‰æ•ˆåœ–ç‰‡å°±åœæ­¢
                        except NoSuchElementException:
                            continue
                    
                    # å¦‚æœé‚„æ˜¯æ²’æ‰¾åˆ°ï¼Œè¨­ç‚ºç©ºå­—ä¸²
                    if not image_url:
                        image_url = ""
                    
                    # ç¢ºä¿æ‰€æœ‰å¿…è¦æ¬„ä½éƒ½æœ‰å€¼æ‰åŠ å…¥å•†å“
                    if title and price > 0 and url:
                        # ä½¿ç”¨ SKU æˆ– URL æª¢æŸ¥æ˜¯å¦é‡è¤‡
                        is_duplicate = False
                        if sku and sku in seen_skus:
                            is_duplicate = True
                        elif url in [p['url'] for p in products]:
                            is_duplicate = True
                        
                        if is_duplicate:
                            #print(f"è·³éé‡è¤‡å•†å“: {sku or url}")
                            consecutive_duplicates += 1
                            # å¦‚æœé€£çºŒé‡è¤‡å¤ªå¤šï¼Œæå‰åœæ­¢è©²é è§£æ
                            if consecutive_duplicates >= max_consecutive_duplicates:
                                print(f"âš ï¸ é€£çºŒ {consecutive_duplicates} å€‹å•†å“éƒ½æ˜¯é‡è¤‡ï¼Œæå‰åœæ­¢è©²é è§£æ")
                                break
                            continue
                        
                        # æ‰¾åˆ°æœ‰æ•ˆæ–°å•†å“ï¼Œé‡ç½®é€£çºŒé‡è¤‡è¨ˆæ•¸
                        consecutive_duplicates = 0
                        
                        product = {
                            "id": product_id,
                            "title": title,
                            "price": price,
                            "image_url": image_url if image_url else "",
                            "url": url,
                            "platform": "momo",
                            "sku": sku
                        }
                        products.append(product)
                        if sku:
                            seen_skus.add(sku)
                        product_id += 1
                        page_products_count += 1
                        
                        # ğŸ“Š å›å ±å³æ™‚é€²åº¦ï¼ˆæ¯æŠ“åˆ°ä¸€å€‹å•†å“å°±æ›´æ–°ï¼‰
                        if progress_callback:
                            progress_callback(
                                len(products), 
                                max_products, 
                                f'ğŸ“¦ MOMO: å·²æ”¶é›† {len(products)}/{max_products} ç­†å•†å“'
                            )
                        
                        #print(f"æˆåŠŸè§£æå•†å“ {len(products)}: {title[:50]}... (NT$ {price:,})")
                    
                    # é¿å…éæ–¼é »ç¹çš„æ“ä½œ
                    time.sleep(random.uniform(0.05, 0.1))
                    
                except Exception as e:
                    print(f"è§£æç¬¬ {i+1} å€‹å•†å“æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            # é¡¯ç¤ºè©³ç´°çµ±è¨ˆ
            if skipped_empty_elements > 0:
                print(f"âš ï¸ è·³é {skipped_empty_elements} å€‹ç©ºå…ƒç´ ï¼ˆå¯èƒ½æ˜¯å»£å‘Šã€åˆ†éš”ç¬¦ç­‰ï¼‰")
            
            print(f"ç¬¬ {page} é æ‰¾åˆ° {len(product_elements)} å€‹å•†å“å…ƒç´ ï¼ŒæˆåŠŸè§£æ {page_products_count} å€‹æœ‰æ•ˆå•†å“ï¼Œç›®å‰ç¸½è¨ˆ {len(products)} å€‹å•†å“")
            
            # ğŸ”§ æ”¹é€²ï¼šåªæœ‰åœ¨ã€Œå·²é”åˆ°ç›®æ¨™æ•¸é‡ã€æˆ–ã€Œé€£çºŒå¤šé éƒ½æ²’æœ‰å•†å“ã€æ™‚æ‰åœæ­¢
            # ç§»é™¤ã€Œå•†å“æ•¸é‡å°‘æ–¼ 20 å°±åœæ­¢ã€çš„é™åˆ¶ï¼Œå› ç‚ºæœ‰äº›é—œéµå­—æœ¬ä¾†å•†å“å°±å°‘
            
            # å¦‚æœé€™ä¸€é æ²’æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆå•†å“ï¼Œæª¢æŸ¥æ˜¯å¦è¦ç¹¼çºŒ
            if page_products_count == 0:
                consecutive_empty_pages += 1
                print(f"âš ï¸ ç¬¬ {page} é æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆå•†å“ï¼ˆé€£çºŒ {consecutive_empty_pages} é ç‚ºç©ºï¼‰")
                
                # å¿«é€Ÿåˆ¤æ–·ï¼šç¬¬ä¸€é å°±æ²’å•†å“ï¼Œç›´æ¥åœæ­¢
                if page == 1 and len(product_elements) < 10:
                    print("âŒ ç¬¬ä¸€é å°±æ²’æœ‰è¶³å¤ å•†å“å…ƒç´ ï¼Œåˆ¤å®šç‚ºæœå°‹çµæœç‚ºç©ºï¼Œåœæ­¢æŠ“å–")
                    break
                # å•†å“å…ƒç´ å¾ˆå°‘æ™‚åœæ­¢ï¼ˆçœŸçš„æ²’å•†å“äº†ï¼‰
                elif len(product_elements) < 10:
                    print("å•†å“å…ƒç´ å¾ˆå°‘ï¼Œåˆ¤å®šç‚ºçœŸæ­£çš„æœ€å¾Œä¸€é ï¼Œåœæ­¢æŠ“å–")
                    break
                # ğŸ†• å¦‚æœä¸æ˜¯ç¬¬ä¸€é ï¼Œä¸”æœ‰å•†å“å…ƒç´ ä½†è§£æå‡º 0 å€‹æœ‰æ•ˆå•†å“ï¼Œç›´æ¥åœæ­¢ï¼ˆé€šå¸¸æ˜¯éƒ½é‡è¤‡äº†ï¼‰
                elif page > 1 and len(product_elements) >= 10:
                    print(f"âŒ ç¬¬ {page} é æœ‰ {len(product_elements)} å€‹å•†å“å…ƒç´ ä½†è§£æå‡º 0 å€‹æœ‰æ•ˆå•†å“ï¼Œåˆ¤å®šç‚ºå·²åˆ°é”æœå°‹çµæœæœ«å°¾ï¼ˆå¯èƒ½éƒ½æ˜¯é‡è¤‡å•†å“ï¼‰ï¼Œåœæ­¢æŠ“å–")
                    break
                # å¦‚æœé€£çºŒ2é éƒ½æ²’æœ‰æœ‰æ•ˆå•†å“ï¼Œåœæ­¢ï¼ˆåŠ å¿«åˆ¤æ–·ï¼‰
                elif consecutive_empty_pages >= 2:
                    print(f"é€£çºŒ {consecutive_empty_pages} é éƒ½æ²’æœ‰æœ‰æ•ˆå•†å“ï¼Œåœæ­¢æŠ“å–")
                    break
                else:
                    print(f"ä½†é é¢é‚„æœ‰å•†å“å…ƒç´ ï¼Œå¯èƒ½åªæ˜¯è¢«éæ¿¾æ‰ï¼ˆä¾‹å¦‚é‡è¤‡SKUï¼‰ï¼Œç¹¼çºŒå˜—è©¦ä¸‹ä¸€é ")
            else:
                # é‡ç½®é€£çºŒç©ºç™½é è¨ˆæ•¸å™¨
                consecutive_empty_pages = 0
                    # ç¹¼çºŒåˆ°ä¸‹ä¸€é å˜—è©¦
                
            # å¦‚æœé‚„éœ€è¦æ›´å¤šå•†å“ï¼Œå‰‡è·³åˆ°ä¸‹ä¸€é 
            if len(products) < max_products:
                page += 1
                print(f"ğŸ“„ æº–å‚™æŠ“å–ç¬¬ {page} é ...")
                time.sleep(random.uniform(1, 1.5))  # é é¢é–“éš”ï¼ˆå¾ 2-3 ç§’æ¸›å°‘åˆ° 1-1.5 ç§’ï¼‰
            else:
                print(f"âœ… å·²é”åˆ°ç›®æ¨™æ•¸é‡ {max_products} ç­†ï¼Œåœæ­¢æŠ“å–")
                break
        
        print(f"æˆåŠŸå¾ momo ç²å– {len(products)} å€‹å”¯ä¸€å•†å“ï¼ˆå·²è‡ªå‹•éæ¿¾é‡è¤‡ SKUï¼‰")
        
        # ğŸ“Š å›å ±å®Œæˆé€²åº¦
        if progress_callback:
            progress_callback(len(products), max_products, f'âœ… MOMO å®Œæˆï¼å…±æ”¶é›† {len(products)} ç­†å•†å“')
        
        return products
        
    except Exception as e:
        error_msg = str(e)
        if "invalid session id" in error_msg:
            print(f"âŒ WebDriver æœƒè©±å¤±æ•ˆï¼ˆç€è¦½å™¨å¯èƒ½å´©æ½°æˆ–è¢«é—œé–‰ï¼‰")
            print("ğŸ’¡ å»ºè­°ï¼šæª¢æŸ¥ç³»çµ±è¨˜æ†¶é«”æ˜¯å¦å……è¶³ï¼Œæˆ–å˜—è©¦æ¸›å°‘æŠ“å–æ•¸é‡")
        elif "target window already closed" in error_msg or "no such window" in error_msg:
            print(f"âŒ Chrome è¦–çª—å·²é—œé–‰ï¼Œç„¡æ³•ç¹¼çºŒæŠ“å–")
        elif "Session info: chrome" in error_msg and "Stacktrace" in error_msg:
            print(f"âŒ Chrome é©…å‹•éŒ¯èª¤ï¼ˆå¯èƒ½æ˜¯è¦–çª—è¢«é—œé–‰æˆ–å´©æ½°ï¼‰")
        else:
            print(f"momo Selenium çˆ¬èŸ²ç™¼ç”ŸéŒ¯èª¤: {e}")
        return products if products else []  # è¿”å›å·²æ”¶é›†çš„å•†å“
    
    finally:
        # ç¢ºä¿é—œé–‰ç€è¦½å™¨
        if driver:
            try:
                driver.quit()
            except:
                pass


def fetch_products_for_pchome(keyword, max_products=50, progress_callback=None, cancel_check=None):
    """
    ä½¿ç”¨ Selenium å¾ PChome è³¼ç‰©ç¶²æŠ“å–å•†å“è³‡è¨Šï¼Œé©æ‡‰ 2025å¹´10æœˆ çš„æ–°ç‰ˆç¶²é çµæ§‹ã€‚
    
    Args:
        keyword (str): æœå°‹é—œéµå­—
        max_products (int): æœ€å¤§æŠ“å–å•†å“æ•¸é‡
        progress_callback (function): é€²åº¦å›èª¿å‡½å¼ï¼Œæ¥æ”¶ (current, total, message) åƒæ•¸
        cancel_check (function): å–æ¶ˆæª¢æŸ¥å‡½å¼ï¼Œè¿”å› True è¡¨ç¤ºéœ€è¦å–æ¶ˆ
    
    Returns:
        list: å•†å“è³‡è¨Šåˆ—è¡¨
    """
    products = []
    product_id = 1
    driver = None
    page = 1
    seen_skus = set()
    consecutive_empty_pages = 0  # é€£çºŒç©ºç™½é è¨ˆæ•¸å™¨

    try:
        chrome_options = Options()
        chrome_options.add_argument('--headless=new')  # ä½¿ç”¨æ–°çš„ç„¡é ­æ¨¡å¼
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-software-rasterizer')
        chrome_options.add_argument('--remote-debugging-port=9223')
        chrome_options.add_argument('--disable-setuid-sandbox')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36')
        
        prefs = {"profile.default_content_setting_values.notifications": 2}
        chrome_options.add_experimental_option("prefs", prefs)
        chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])
        
        # è¨­å®šé é¢è¼‰å…¥ç­–ç•¥ï¼ˆä¸ç­‰å¾…å…¨éƒ¨è³‡æºï¼‰
        chrome_options.page_load_strategy = 'eager'
        
        # åˆå§‹åŒ– WebDriverï¼ˆè‡ªå‹•ä¸‹è¼‰ä¸¦ä½¿ç”¨ ChromeDriverï¼‰
        try:
            # ä½¿ç”¨ webdriver_manager è‡ªå‹•ç®¡ç† chromedriver
            chromedriver_path = ChromeDriverManager().install()
            
            # è¨­å®šåŸ·è¡Œæ¬Šé™ï¼ˆWindows ä¸Šé€šå¸¸ä¸éœ€è¦ï¼Œä½†åŠ ä¸Šç¢ºä¿æ²’å•é¡Œï¼‰
            service = Service(chromedriver_path)
            driver = webdriver.Chrome(service=service, options=chrome_options)
        except Exception as driver_error:
            print(f"âš ï¸ ChromeDriver åˆå§‹åŒ–å¤±æ•—: {driver_error}")
            print("ğŸ’¡ å˜—è©¦ä½¿ç”¨ç³»çµ± PATH ä¸­çš„ ChromeDriver...")
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ç³»çµ±ä¸­çš„ chromedriver
            driver = webdriver.Chrome(options=chrome_options)
        
        driver.set_page_load_timeout(60)  # å¢åŠ åˆ° 60 ç§’
        wait = WebDriverWait(driver, 30)  # å¢åŠ åˆ° 30 ç§’
        print(f"æ­£åœ¨æœå°‹ PChome: {keyword}")
        
        # ğŸ“Š å›å ±åˆå§‹é€²åº¦
        if progress_callback:
            progress_callback(0, max_products, f'ğŸ” æ­£åœ¨æœå°‹ PChome: {keyword}')

        encoded_keyword = quote(keyword)
        search_url = f"https://24h.pchome.com.tw/search/?q={encoded_keyword}"
        
        # è¼‰å…¥åˆå§‹é é¢ï¼ˆåŠ å…¥é‡è©¦æ©Ÿåˆ¶ï¼‰
        retry_count = 0
        max_retries = 3
        page_loaded = False
        
        while retry_count < max_retries and not page_loaded:
            try:
                # æª¢æŸ¥ driver æœƒè©±æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                try:
                    _ = driver.current_url
                except Exception as session_error:
                    print(f"âš ï¸ WebDriver æœƒè©±å¤±æ•ˆï¼Œé‡æ–°åˆå§‹åŒ–ç€è¦½å™¨...")
                    try:
                        driver.quit()
                    except:
                        pass
                    driver = webdriver.Chrome(service=service, options=chrome_options)
                    driver.set_page_load_timeout(60)
                    wait = WebDriverWait(driver, 30)
                
                driver.get(search_url)
                time.sleep(2)
                page_loaded = True
            except Exception as e:
                retry_count += 1
                error_msg = str(e)
                if "invalid session id" in error_msg:
                    print(f"âš ï¸ æœƒè©±å¤±æ•ˆ (å˜—è©¦ {retry_count}/{max_retries})ï¼Œé‡æ–°åˆå§‹åŒ–ç€è¦½å™¨...")
                    try:
                        driver.quit()
                    except:
                        pass
                    # é‡æ–°å‰µå»º driver
                    driver = webdriver.Chrome(service=service, options=chrome_options)
                    driver.set_page_load_timeout(60)
                    wait = WebDriverWait(driver, 30)
                    time.sleep(2)
                elif "ERR_INTERNET_DISCONNECTED" in error_msg or "ERR_CONNECTION" in error_msg:
                    print(f"âš ï¸ ç¶²è·¯é€£ç·šéŒ¯èª¤ (å˜—è©¦ {retry_count}/{max_retries})ï¼Œç­‰å¾… 3 ç§’å¾Œé‡è©¦...")
                    time.sleep(3)
                else:
                    print(f"âŒ é é¢è¼‰å…¥éŒ¯èª¤: {e}")
                    break
        
        if not page_loaded:
            print("âŒ PChome åˆå§‹é é¢è¼‰å…¥å¤±æ•—ï¼Œåœæ­¢æŠ“å–")
            return []

        while len(products) < max_products:
            # æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
            if cancel_check and cancel_check():
                print("âŒ PChome æœå°‹å·²è¢«å–æ¶ˆ")
                break
            
            print(f"æ­£åœ¨æŠ“å– PChome ç¬¬ {page} é ...")
            
            # ğŸ“Š å›å ±é é¢è¼‰å…¥é€²åº¦
            if progress_callback:
                progress_callback(len(products), max_products, f'(å·²æ”¶é›† {len(products)}/{max_products} ç­†)')
            
            try:
                # ğŸ” æª¢æŸ¥ WebDriver æœƒè©±æ˜¯å¦é‚„æœ‰æ•ˆ
                try:
                    _ = driver.current_url
                except Exception as session_error:
                    print(f"âš ï¸ æª¢æ¸¬åˆ°æœƒè©±å¤±æ•ˆï¼Œå˜—è©¦æ¢å¾©...")
                    # æœƒè©±å¤±æ•ˆï¼Œå˜—è©¦é‡æ–°å‰µå»º driver
                    try:
                        driver.quit()
                    except:
                        pass
                    print("ğŸ”„ é‡æ–°åˆå§‹åŒ–ç€è¦½å™¨...")
                    driver = webdriver.Chrome(service=service, options=chrome_options)
                    driver.set_page_load_timeout(60)
                    wait = WebDriverWait(driver, 30)
                    # é‡æ–°è¼‰å…¥ç•¶å‰é é¢
                    driver.get(search_url)
                    time.sleep(3)
                
                # ç­‰å¾…æ–°çµæ§‹çš„å•†å“é …ç›®å‡ºç¾
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "li.c-listInfoGrid__item--gridCardGray5")))
                
                # æ»¾å‹•é é¢ä»¥ç¢ºä¿æ‰€æœ‰å•†å“éƒ½è¼‰å…¥
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # æ ¹æ“šæ–°çµæ§‹ç²å–æ‰€æœ‰å•†å“å…ƒç´ 
                product_elements = driver.find_elements(By.CSS_SELECTOR, "li.c-listInfoGrid__item--gridCardGray5")
            except TimeoutException:
                print("é é¢åŠ è¼‰è¶…æ™‚æˆ–æ‰¾ä¸åˆ°æ–°çµæ§‹çš„å•†å“å®¹å™¨ (li.c-listInfoGrid__item--gridCardGray5)ã€‚")
                try:
                    driver.save_screenshot("pchome_error_screenshot.png")
                    print("å·²å„²å­˜éŒ¯èª¤æˆªåœ–: pchome_error_screenshot.png")
                except Exception as e:
                    print(f"å„²å­˜æˆªåœ–å¤±æ•—: {e}")
                break

            print(f"ç¬¬ {page} é æ‰¾åˆ° {len(product_elements)} å€‹å•†å“å…ƒç´ ")
            
            # è¨˜éŒ„é€™ä¸€é æˆåŠŸè§£æçš„å•†å“æ•¸
            page_products_count = 0
            consecutive_duplicates = 0  # é€£çºŒé‡è¤‡å•†å“è¨ˆæ•¸å™¨
            max_consecutive_duplicates = 10  # é€£çºŒ 10 å€‹é‡è¤‡å°±åœæ­¢è©²é 

            for element in product_elements:
                # æª¢æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                if cancel_check and cancel_check():
                    print("âŒ PChome æœå°‹å·²è¢«å–æ¶ˆ")
                    break
                
                if len(products) >= max_products:
                    break

                try:
                    # æå–é€£çµå’Œ SKU
                    link_element = element.find_element(By.CSS_SELECTOR, "a.c-prodInfoV2__link")
                    url = link_element.get_attribute("href")
                    if not url.startswith("https://"):
                        url = "https://24h.pchome.com.tw" + url
                    
                    sku_match = re.search(r'/prod/(.*?)(?:\?|$)', url)
                    sku = sku_match.group(1) if sku_match else ""

                    # æå–æ¨™é¡Œ
                    title_elem = element.find_element(By.CSS_SELECTOR, "h3.c-prodInfoV2__title")
                    title = title_elem.text.strip()

                    # æå–åƒ¹æ ¼ - å„ªå…ˆæŠ“å–ä¿ƒéŠ·åƒ¹ï¼ˆæ‰“æŠ˜å¾Œçš„åƒ¹æ ¼ï¼‰è€ŒéåŸåƒ¹
                    price = 0
                    prices = []
                    installment_prices = []  # åˆ†é–‹è¨˜éŒ„ç–‘ä¼¼åˆ†æœŸçš„åƒ¹æ ¼
                    
                    # æ–¹æ³•1: æ‰¾æ‰€æœ‰åŒ…å« "o-prodPrice" çš„ div å…ƒç´ 
                    try:
                        price_divs = element.find_elements(By.CSS_SELECTOR, "div[class*='o-prodPrice']")
                        for price_div in price_divs:
                            price_text = price_div.text.strip()
                            
                            # ğŸš« è·³éåŒ…å«åˆ†æœŸé—œéµå­—çš„æ–‡å­—ï¼ˆä½†è¨˜éŒ„ä¸‹ä¾†ä»¥ä¾¿åˆ¤æ–·ï¼‰
                            if any(keyword in price_text for keyword in ['æœŸ', 'x', 'X', '/', 'æ¯æœŸ']):
                                # ä»ç„¶æå–æ•¸å­—ï¼Œä½†æ¨™è¨˜ç‚ºåˆ†æœŸåƒ¹æ ¼
                                price_text_clean = price_text.replace(',', '').replace('$', '').replace('å…ƒ', '').strip()
                                price_match = re.search(r'(\d+)', price_text_clean)
                                if price_match:
                                    potential_price = int(price_match.group(1))
                                    if 100 < potential_price < 10000000:
                                        installment_prices.append(potential_price)
                                continue
                            
                            # ç§»é™¤é€—è™Ÿä¸¦æå–å®Œæ•´çš„åƒ¹æ ¼æ•¸å­—
                            price_text_clean = price_text.replace(',', '').replace('$', '').replace('å…ƒ', '').strip()
                            price_match = re.search(r'(\d+)', price_text_clean)
                            if price_match:
                                potential_price = int(price_match.group(1))
                                # åªæ”¶é›†åˆç†çš„å•†å“åƒ¹æ ¼ï¼ˆæ’é™¤éå°æˆ–éå¤§çš„ç•°å¸¸å€¼ï¼‰
                                if 100 < potential_price < 10000000:
                                    prices.append(potential_price)
                    except:
                        pass
                    
                    # æ–¹æ³•2: æ‰¾æ‰€æœ‰åŒ…å« $ ç¬¦è™Ÿçš„æ–‡å­—ï¼ˆä½†æ’é™¤åˆ†æœŸç›¸é—œï¼‰
                    if not prices:
                        try:
                            all_text = element.text
                            # å°‡æ–‡å­—æŒ‰è¡Œåˆ†å‰²ï¼Œé€è¡Œæª¢æŸ¥
                            lines = all_text.split('\n')
                            for line in lines:
                                # ğŸš« è·³éåŒ…å«åˆ†æœŸé—œéµå­—çš„è¡Œ
                                if any(keyword in line for keyword in ['æœŸ', 'x', 'X', '/', 'æ¯æœŸ', 'åˆ†æœŸ']):
                                    continue
                                
                                # æ‰¾æ‰€æœ‰ $æ•¸å­— çš„æ¨¡å¼
                                price_matches = re.findall(r'\$[\d,]+', line)
                                for match in price_matches:
                                    price_num = int(re.sub(r'[^\d]', '', match))
                                    if 100 < price_num < 10000000:
                                        prices.append(price_num)
                        except:
                            pass
                    
                    # æ–¹æ³•3: å„ªå…ˆæ‰¾ã€Œå”®åƒ¹ã€å…ƒç´ ï¼ˆæœ€æº–ç¢ºï¼‰
                    if not prices:
                        try:
                            price_elem = element.find_element(By.CSS_SELECTOR, "div.c-prodInfoV2__salePrice")
                            price_text = price_elem.text.strip()
                            price_text_clean = price_text.replace(',', '').replace('$', '').replace('å…ƒ', '').strip()
                            price_match = re.search(r'(\d+)', price_text_clean)
                            if price_match:
                                potential_price = int(price_match.group(1))
                                if potential_price > 100:
                                    prices.append(potential_price)
                        except:
                            pass
                    
                    # æ™ºæ…§é¸æ“‡åƒ¹æ ¼ï¼š
                    # 1. å¦‚æœåªæœ‰ä¸€å€‹åƒ¹æ ¼ï¼Œç›´æ¥ä½¿ç”¨
                    # 2. å¦‚æœæœ‰å¤šå€‹åƒ¹æ ¼ï¼ˆåŸåƒ¹+ä¿ƒéŠ·åƒ¹ï¼‰ï¼Œé¸æ“‡æœ€å°çš„ï¼ˆä¿ƒéŠ·åƒ¹ï¼‰
                    # 3. ä½†è¦ç¢ºä¿é¸æ“‡çš„åƒ¹æ ¼ä¸æ˜¯åˆ†æœŸä»˜æ¬¾é‡‘é¡
                    if prices:
                        if len(prices) == 1:
                            price = prices[0]
                        else:
                            # æœ‰å¤šå€‹åƒ¹æ ¼æ™‚ï¼Œé¸æ“‡è¼ƒå°çš„ï¼ˆé€šå¸¸æ˜¯ä¿ƒéŠ·åƒ¹ï¼‰
                            candidate_price = min(prices)
                            # ç¢ºä¿é€™å€‹åƒ¹æ ¼ä¸æ˜¯åˆ†æœŸä»˜æ¬¾é‡‘é¡
                            # å¦‚æœæœ€å°åƒ¹æ ¼å‰›å¥½ç­‰æ–¼æŸå€‹åˆ†æœŸé‡‘é¡ï¼Œå‰‡ä½¿ç”¨ç¬¬äºŒå°çš„
                            if installment_prices and candidate_price in installment_prices:
                                # æ’é™¤åˆ†æœŸé‡‘é¡å¾Œå†é¸æ“‡
                                valid_prices = [p for p in prices if p not in installment_prices]
                                if valid_prices:
                                    price = min(valid_prices)
                                else:
                                    # å¦‚æœæ’é™¤å¾Œæ²’æœ‰åƒ¹æ ¼ï¼Œå‰‡å–æœ€å¤§çš„ï¼ˆåŸåƒ¹ï¼‰
                                    price = max(prices)
                            else:
                                price = candidate_price
                    else:
                        price = 0

                    # æå–åœ–ç‰‡ - ä½¿ç”¨å¤šé‡ç­–ç•¥æé«˜æˆåŠŸç‡
                    image_url = ""
                    
                    # åœ–ç‰‡é¸æ“‡å™¨åˆ—è¡¨ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰
                    img_selectors = [
                        "img[data-regression='store_prodImg']",  # 2025 æœ€æ–°çµæ§‹
                        "a.c-prodInfoV2__link img",              # é€£çµä¸­çš„åœ–ç‰‡ï¼ˆå„ªå…ˆï¼‰
                        "div.c-prodInfoV2__head img",            # å•†å“é ­éƒ¨åœ–ç‰‡
                        "img[src*='items']",                     # PChome å•†å“åœ–ç‰‡è·¯å¾‘
                        "img[src*='pchome.com.tw']",            # PChome åŸŸååœ–ç‰‡
                        "div.c-prodInfo__img img",
                        "img[data-src*='items']",                # å»¶é²è¼‰å…¥çš„å•†å“åœ–ç‰‡
                        "img[data-src*='pchome']",
                        "img[data-original*='items']",
                        "img[alt]",                              # ä»»ä½•æœ‰ alt å±¬æ€§çš„åœ–ç‰‡
                        "img"                                    # æœ€å¾Œå‚™é¸ï¼šä»»ä½•åœ–ç‰‡
                    ]
                    
                    for selector in img_selectors:
                        try:
                            img_elem = element.find_element(By.CSS_SELECTOR, selector)
                            
                            # å˜—è©¦å¤šå€‹å±¬æ€§ä¾†ç²å–åœ–ç‰‡ç¶²å€ï¼ˆæŒ‰å„ªå…ˆé †åºï¼‰
                            potential_urls = [
                                img_elem.get_attribute("src"),
                                img_elem.get_attribute("data-src"),
                                img_elem.get_attribute("data-original"),
                                img_elem.get_attribute("data-lazy"),
                                img_elem.get_attribute("data-lazy-src"),
                                img_elem.get_attribute("srcset")  # æœ‰æ™‚åœ–ç‰‡åœ¨ srcset ä¸­
                            ]
                            
                            for url in potential_urls:
                                if not url:
                                    continue
                                    
                                # å¦‚æœæ˜¯ srcsetï¼Œæå–ç¬¬ä¸€å€‹ URL
                                if 'srcset' in selector or ',' in url:
                                    url = url.split(',')[0].strip().split(' ')[0]
                                
                                # æ’é™¤ç„¡æ•ˆçš„åœ–ç‰‡
                                if (url and url != "" and 
                                    "placeholder" not in url.lower() and 
                                    url != "about:blank" and 
                                    not url.startswith("data:image") and
                                    len(url) > 10):  # ç¢ºä¿ URL æœ‰è¶³å¤ é•·åº¦
                                    
                                    image_url = url
                                    break
                            
                            if image_url:  # æ‰¾åˆ°æœ‰æ•ˆåœ–ç‰‡å°±åœæ­¢
                                break
                                
                        except NoSuchElementException:
                            continue
                        except Exception as e:
                            # å¿½ç•¥å…¶ä»–éŒ¯èª¤ï¼Œç¹¼çºŒå˜—è©¦ä¸‹ä¸€å€‹é¸æ“‡å™¨
                            continue
                    
                    # è™•ç†åœ–ç‰‡ URL
                    if image_url:
                        # è™•ç†ç›¸å°è·¯å¾‘å’Œå”è­°ç›¸å°è·¯å¾‘
                        if image_url.startswith("//"):
                            image_url = "https:" + image_url
                        elif image_url.startswith("/"):
                            image_url = "https://24h.pchome.com.tw" + image_url
                        elif not image_url.startswith("http"):
                            if "pchome" not in image_url:
                                image_url = "https://img.pchome.com.tw/" + image_url
                            else:
                                image_url = "https://" + image_url
                    
                    # å¦‚æœé‚„æ˜¯æ²’æ‰¾åˆ°åœ–ç‰‡ï¼Œå˜—è©¦å¾ JavaScript è®Šæ•¸æˆ– JSON ä¸­æå–
                    if not image_url:
                        try:
                            # å˜—è©¦å¾å…ƒç´ çš„ data å±¬æ€§ä¸­æ‰¾
                            for attr in ['data-image', 'data-img', 'data-pic', 'data-photo']:
                                test_url = element.get_attribute(attr)
                                if test_url and len(test_url) > 10 and test_url.startswith('http'):
                                    image_url = test_url
                                    break
                        except:
                            pass
                    
                    # æœ€çµ‚è¨­ç‚ºç©ºå­—ä¸²ï¼ˆå¦‚æœä»æœªæ‰¾åˆ°ï¼‰
                    if not image_url:
                        image_url = ""

                    if title and price > 0 and url and sku:
                        # ä½¿ç”¨ SKU æˆ– URL æª¢æŸ¥æ˜¯å¦é‡è¤‡
                        is_duplicate = False
                        if sku in seen_skus:
                            is_duplicate = True
                        elif url in [p['url'] for p in products]:
                            is_duplicate = True
                        
                        if is_duplicate:
                            consecutive_duplicates += 1
                            # å¦‚æœé€£çºŒé‡è¤‡å¤ªå¤šï¼Œæå‰åœæ­¢è©²é è§£æ
                            if consecutive_duplicates >= max_consecutive_duplicates:
                                print(f"âš ï¸ é€£çºŒ {consecutive_duplicates} å€‹å•†å“éƒ½æ˜¯é‡è¤‡ï¼Œæå‰åœæ­¢è©²é è§£æ")
                                break
                            continue
                        
                        # æ‰¾åˆ°æœ‰æ•ˆæ–°å•†å“ï¼Œé‡ç½®é€£çºŒé‡è¤‡è¨ˆæ•¸
                        consecutive_duplicates = 0
                        
                        seen_skus.add(sku)
                        product = {
                            "id": product_id,
                            "title": title,
                            "price": price,
                            "image_url": image_url,
                            "url": url,
                            "platform": "pchome",
                            "sku": sku
                        }
                        products.append(product)
                        product_id += 1
                        page_products_count += 1  # è¨˜éŒ„é€™ä¸€é æˆåŠŸè§£æçš„å•†å“æ•¸
                        
                        # ğŸ“Š å›å ±å³æ™‚é€²åº¦ï¼ˆæ¯æŠ“åˆ°ä¸€å€‹å•†å“å°±æ›´æ–°ï¼‰
                        if progress_callback:
                            progress_callback(
                                len(products), 
                                max_products, 
                                f'ğŸ“¦ PChome: å·²æ”¶é›† {len(products)}/{max_products} ç­†å•†å“'
                            )

                except (NoSuchElementException, ValueError) as e:
                    continue
            
            print(f"ç¬¬ {page} é æ‰¾åˆ° {len(product_elements)} å€‹å•†å“å…ƒç´ ï¼ŒæˆåŠŸè§£æ {page_products_count} å€‹æœ‰æ•ˆå•†å“ï¼Œç›®å‰ç¸½è¨ˆ {len(products)} å€‹å•†å“")
            
            # ğŸ”§ æ”¹é€²ï¼šæ™ºæ…§åœæ­¢åˆ¤æ–·
            if page_products_count == 0:
                consecutive_empty_pages += 1
                print(f"âš ï¸ ç¬¬ {page} é æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆå•†å“ï¼ˆé€£çºŒ {consecutive_empty_pages} é ç‚ºç©ºï¼‰")
                
                # å¿«é€Ÿåˆ¤æ–·ï¼šç¬¬ä¸€é å°±æ²’å•†å“ï¼Œç›´æ¥åœæ­¢
                if page == 1 and len(product_elements) < 10:
                    print("âŒ ç¬¬ä¸€é å°±æ²’æœ‰è¶³å¤ å•†å“å…ƒç´ ï¼Œåˆ¤å®šç‚ºæœå°‹çµæœç‚ºç©ºï¼Œåœæ­¢æŠ“å–")
                    break
                # å•†å“å…ƒç´ å¾ˆå°‘æ™‚åœæ­¢ï¼ˆçœŸçš„æ²’å•†å“äº†ï¼‰
                elif len(product_elements) < 10:
                    print("å•†å“å…ƒç´ å¾ˆå°‘ï¼Œåˆ¤å®šç‚ºçœŸæ­£çš„æœ€å¾Œä¸€é ï¼Œåœæ­¢æŠ“å–")
                    break
                # ğŸ†• å¦‚æœä¸æ˜¯ç¬¬ä¸€é ï¼Œä¸”æœ‰å•†å“å…ƒç´ ä½†è§£æå‡º 0 å€‹æœ‰æ•ˆå•†å“ï¼Œç›´æ¥åœæ­¢ï¼ˆé€šå¸¸æ˜¯éƒ½é‡è¤‡äº†ï¼‰
                elif page > 1 and len(product_elements) >= 10:
                    print(f"âŒ ç¬¬ {page} é æœ‰ {len(product_elements)} å€‹å•†å“å…ƒç´ ä½†è§£æå‡º 0 å€‹æœ‰æ•ˆå•†å“ï¼Œåˆ¤å®šç‚ºå·²åˆ°é”æœå°‹çµæœæœ«å°¾ï¼ˆå¯èƒ½éƒ½æ˜¯é‡è¤‡å•†å“ï¼‰ï¼Œåœæ­¢æŠ“å–")
                    break
                # å¦‚æœé€£çºŒ2é éƒ½æ²’æœ‰æœ‰æ•ˆå•†å“ï¼Œåœæ­¢ï¼ˆåŠ å¿«åˆ¤æ–·ï¼‰
                elif consecutive_empty_pages >= 2:
                    print(f"é€£çºŒ {consecutive_empty_pages} é éƒ½æ²’æœ‰æœ‰æ•ˆå•†å“ï¼Œåœæ­¢æŠ“å–")
                    break
                else:
                    print(f"ä½†é é¢é‚„æœ‰å•†å“å…ƒç´ ï¼Œå¯èƒ½åªæ˜¯è¢«éæ¿¾æ‰ï¼ˆä¾‹å¦‚é‡è¤‡SKUï¼‰ï¼Œç¹¼çºŒå˜—è©¦ä¸‹ä¸€é ")
            else:
                # é‡ç½®é€£çºŒç©ºç™½é è¨ˆæ•¸å™¨
                consecutive_empty_pages = 0
            
            # å¦‚æœå·²é”åˆ°ç›®æ¨™æ•¸é‡å°±åœæ­¢
            if len(products) >= max_products:
                print(f"âœ… å·²é”åˆ°ç›®æ¨™æ•¸é‡ {max_products} ç­†ï¼Œåœæ­¢æŠ“å–")
                break

            # é»æ“Šä¸‹ä¸€é æŒ‰éˆ•
            try:
                # å…ˆæ»¾å‹•åˆ°é é¢åº•éƒ¨ï¼Œç¢ºä¿ä¸‹ä¸€é æŒ‰éˆ•å¯è¦‹
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1)
                
                # ä½¿ç”¨æ–°çš„é¸æ“‡å™¨ä¾†æ‰¾åˆ°ä¸‹ä¸€é æŒ‰éˆ•
                # æ ¹æ“š HTML çµæ§‹ï¼Œå°‹æ‰¾åŒ…å«å‘å³ç®­é ­åœ–ç¤ºçš„å…ƒç´ 
                next_icon = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "i.o-iconFonts--arrowSolidRight")))
                # é»æ“Šåœ–ç¤ºçš„çˆ¶å…ƒç´ ï¼ˆæ‡‰è©²æ˜¯å¯é»æ“Šçš„æŒ‰éˆ•ï¼‰
                next_page_button = next_icon.find_element(By.XPATH, "..")
                driver.execute_script("arguments[0].click();", next_page_button)
                page += 1
                time.sleep(random.uniform(3, 5))
            except (TimeoutException, NoSuchElementException):
                print("æ‰¾ä¸åˆ°ä¸‹ä¸€é æŒ‰éˆ•ï¼ŒæŠ“å–çµæŸã€‚")
                break
        
        print(f"æˆåŠŸå¾ PChome ç²å– {len(products)} å€‹å”¯ä¸€å•†å“ã€‚")
        
        # ğŸ“Š å›å ±å®Œæˆé€²åº¦
        if progress_callback:
            progress_callback(len(products), max_products, f'âœ… PChome å®Œæˆï¼å…±æ”¶é›† {len(products)} ç­†å•†å“')
        
        return products

    except Exception as e:
        error_msg = str(e)
        if "invalid session id" in error_msg:
            print(f"âŒ WebDriver æœƒè©±å¤±æ•ˆï¼ˆç€è¦½å™¨å¯èƒ½å´©æ½°æˆ–è¢«é—œé–‰ï¼‰")
            print("ğŸ’¡ å»ºè­°ï¼šæª¢æŸ¥ç³»çµ±è¨˜æ†¶é«”æ˜¯å¦å……è¶³ï¼Œæˆ–å˜—è©¦æ¸›å°‘æŠ“å–æ•¸é‡")
        elif "target window already closed" in error_msg or "no such window" in error_msg:
            print(f"âŒ Chrome è¦–çª—å·²é—œé–‰ï¼Œç„¡æ³•ç¹¼çºŒæŠ“å–")
        elif "Session info: chrome" in error_msg and "Stacktrace" in error_msg:
            print(f"âŒ Chrome é©…å‹•éŒ¯èª¤ï¼ˆå¯èƒ½æ˜¯è¦–çª—è¢«é—œé–‰æˆ–å´©æ½°ï¼‰")
        else:
            print(f"PChome Selenium çˆ¬èŸ²ç™¼ç”ŸéŒ¯èª¤: {e}")
        return products if products else []  # è¿”å›å·²æ”¶é›†çš„å•†å“

    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass


def save_to_csv(products, filename, query_keyword, append_mode=True):
    """
    å°‡å•†å“è³‡è¨Šå„²å­˜ç‚ºCSVæ ¼å¼
    
    Args:
        products (list): å•†å“è³‡è¨Šåˆ—è¡¨
        filename (str): CSVæª”æ¡ˆåç¨±
        query_keyword (str): æŸ¥è©¢é—œéµå­—
        append_mode (bool): True=è¿½åŠ æ¨¡å¼ï¼ŒFalse=è¦†è“‹æ¨¡å¼
    """
    if not products:
        print(f"æ²’æœ‰å•†å“è³‡æ–™å¯ä»¥å„²å­˜åˆ° {filename}")
        return
    
    # CSVæ¬„ä½å®šç¾©ï¼ˆèˆ‡ä½ çš„CSVæ ¼å¼ä¸€è‡´ï¼‰
    fieldnames = [
        'id', 'sku', 'title', 'image', 'url', 'platform', 
        'connect', 'price', 'uncertainty_problem', 'query', 
        'annotator', 'created_at', 'updated_at'
    ]
    
    # ç•¶å‰æ™‚é–“
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ï¼Œä»¥åŠæ˜¯å¦éœ€è¦è¿½åŠ 
    file_exists = os.path.exists(filename)
    
    # å¦‚æœæ˜¯è¿½åŠ æ¨¡å¼ä¸”æª”æ¡ˆå­˜åœ¨ï¼Œéœ€è¦å…ˆè®€å–ç¾æœ‰çš„æœ€å¤§ id
    start_id = 1
    if append_mode and file_exists:
        try:
            import pandas as pd
            existing_df = pd.read_csv(filename)
            if not existing_df.empty and 'id' in existing_df.columns:
                start_id = existing_df['id'].max() + 1
        except Exception as e:
            print(f"è®€å–ç¾æœ‰æª”æ¡ˆå¤±æ•—ï¼Œå°‡å¾ id=1 é–‹å§‹: {e}")
            start_id = 1
    
    # æ±ºå®šé–‹å•Ÿæ¨¡å¼ï¼šè¿½åŠ æˆ–è¦†è“‹
    mode = 'a' if (append_mode and file_exists) else 'w'
    
    with open(filename, mode, newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        
        # åªæœ‰åœ¨æ–°å»ºæª”æ¡ˆæˆ–è¦†è“‹æ¨¡å¼æ™‚æ‰å¯«å…¥è¡¨é ­
        if mode == 'w':
            writer.writeheader()
        
        for i, product in enumerate(products):
            # æ§‹å»ºCSVè¡Œè³‡æ–™ï¼ˆåŒ¹é…ä½ çš„æ ¼å¼ï¼‰
            row = {
                'id': start_id + i,  # ä½¿ç”¨é€£çºŒçš„ id
                'sku': product['sku'],
                'title': product['title'],
                'image': product['image_url'],
                'url': product['url'],
                'platform': product['platform'],
                'connect': '',  # ç©ºå€¼ï¼Œå¦‚æœéœ€è¦å¯ä»¥å¾ŒçºŒå¡«å…¥
                'price': f"{product['price']:.2f}",
                'uncertainty_problem': '0',
                'query': query_keyword,
                'annotator': 'model_prediction',
                'created_at': current_time,
                'updated_at': current_time
            }
            writer.writerow(row)
    
    print(f"âœ… æˆåŠŸå„²å­˜ {len(products)} ç­†å•†å“è‡³ {filename}")


if __name__ == "__main__":
    # æ¸¬è©¦çˆ¬èŸ²
    keyword = input("è¼¸å…¥é—œéµå­—: ")
    english_keyword = input("è¼¸å…¥é—œéµå­—çš„è‹±æ–‡åç¨±: ")
    num = int(input("è¼¸å…¥æ•¸é‡: "))
    
    # æŠ“å– MOMO å•†å“
    print("\n=== é–‹å§‹æŠ“å– MOMO å•†å“ ===")
    momo_products = fetch_products_for_momo(keyword, num)
    
    # å„²å­˜ MOMO å•†å“è‡³ CSV æª”æ¡ˆ
    save_to_csv(momo_products, "momo.csv", english_keyword)

    if momo_products:
        print(f"\næ‰¾åˆ° {len(momo_products)} å€‹ MOMO å•†å“ï¼š")
        for product in momo_products[:5]:  # åªé¡¯ç¤ºå‰5å€‹
            print(f"ID: {product['id']}")
            print(f"æ¨™é¡Œ: {product['title']}")
            print(f"åƒ¹æ ¼: NT$ {product['price']:,}")
            print(f"åœ–ç‰‡: {product['image_url']}")
            print(f"é€£çµ: {product['url']}")
            print(f"å¹³å°: {product['platform']}")
            print("-" * 50)
        if len(momo_products) > 5:
            print(f"... ä»¥åŠå…¶ä»– {len(momo_products) - 5} å€‹å•†å“")
    else:
        print("æ²’æœ‰æ‰¾åˆ° MOMO å•†å“")

    # æŠ“å– PChome å•†å“
    print("\n=== é–‹å§‹æŠ“å– PChome å•†å“ ===")
    pchome_products = fetch_products_for_pchome(keyword, num)
    
    # å„²å­˜ PChome å•†å“è‡³ CSV æª”æ¡ˆ
    save_to_csv(pchome_products, "pchome.csv", english_keyword)

    if pchome_products:
        print(f"\næ‰¾åˆ° {len(pchome_products)} å€‹ PChome å•†å“ï¼š")
        for product in pchome_products[:5]:  # åªé¡¯ç¤ºå‰5å€‹
            print(f"ID: {product['id']}")
            print(f"æ¨™é¡Œ: {product['title']}")
            print(f"åƒ¹æ ¼: NT$ {product['price']:,}")
            print(f"åœ–ç‰‡: {product['image_url']}")
            print(f"é€£çµ: {product['url']}")
            print(f"å¹³å°: {product['platform']}")
            print("-" * 50)
        if len(pchome_products) > 5:
            print(f"... ä»¥åŠå…¶ä»– {len(pchome_products) - 5} å€‹å•†å“")
    else:
        print("æ²’æœ‰æ‰¾åˆ° PChome å•†å“")
    
    print(f"\n=== å®Œæˆï¼===")
    print(f"MOMO å•†å“å·²å„²å­˜è‡³: momo.csv")
    print(f"PChome å•†å“å·²å„²å­˜è‡³: pchome.csv")