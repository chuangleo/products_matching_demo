"""
é å…ˆè¨ˆç®—ç¬¬ä¸€éšæ®µç›¸ä¼¼åº¦æ¨¡çµ„
åœ¨çˆ¬èŸ²å®Œæˆå¾Œè‡ªå‹•è¨ˆç®—æ‰€æœ‰ MOMO èˆ‡ PChome å•†å“ä¹‹é–“çš„ç›¸ä¼¼åº¦
"""
import pandas as pd
import numpy as np
import torch
from sentence_transformers import SentenceTransformer
import os
import json
from datetime import datetime


def prepare_text(title, platform):
    """æº–å‚™æ–‡æœ¬ç”¨æ–¼ç·¨ç¢¼"""
    return ("query: " if platform == 'momo' else "passage: ") + str(title)


def get_batch_embeddings(model, texts, batch_size=32):
    """æ‰¹æ¬¡è¨ˆç®— embeddings"""
    return model.encode(texts, convert_to_tensor=True, batch_size=batch_size).cpu()


def calculate_similarities_for_all(model, momo_df, pchome_df, threshold=0.739465):
    """
    è¨ˆç®—æ‰€æœ‰å•†å“çš„ç›¸ä¼¼åº¦
    
    Args:
        model: SentenceTransformer æ¨¡å‹
        momo_df: MOMO å•†å“ DataFrame
        pchome_df: PChome å•†å“ DataFrame
        threshold: ç›¸ä¼¼åº¦é–€æª»
    
    Returns:
        dict: {momo_id: [{pchome_id, similarity, ...}]} æ ¼å¼çš„ç›¸ä¼¼åº¦çµæœ
    """
    print(f"\nğŸ”„ é–‹å§‹è¨ˆç®—æ‰€æœ‰å•†å“çš„ç›¸ä¼¼åº¦...")
    
    momo_products = momo_df.reset_index(drop=True)
    pchome_products = pchome_df.reset_index(drop=True)
    
    if momo_products.empty or pchome_products.empty:
        print(f"âš ï¸ å•†å“æ•¸æ“šä¸è¶³ï¼Œè·³é")
        return {}
    
    print(f"  MOMO å•†å“æ•¸: {len(momo_products)}, PChome å•†å“æ•¸: {len(pchome_products)}")
    
    # æº–å‚™æ–‡æœ¬
    momo_texts = [prepare_text(row['title'], 'momo') for _, row in momo_products.iterrows()]
    pchome_texts = [prepare_text(row['title'], 'pchome') for _, row in pchome_products.iterrows()]
    
    # è¨ˆç®— embeddings
    print("  ğŸ“Š è¨ˆç®— MOMO å•†å“ç‰¹å¾µå‘é‡...")
    momo_embs = get_batch_embeddings(model, momo_texts)
    print("  ğŸ“Š è¨ˆç®— PChome å•†å“ç‰¹å¾µå‘é‡...")
    pchome_embs = get_batch_embeddings(model, pchome_texts)
    
    # æ­£è¦åŒ–
    momo_embs = torch.nn.functional.normalize(momo_embs, p=2, dim=1)
    pchome_embs = torch.nn.functional.normalize(pchome_embs, p=2, dim=1)
    
    # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
    print("  ğŸ” è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£...")
    similarity_matrix = torch.mm(momo_embs, pchome_embs.T).numpy()
    
    # æ•´ç†çµæœï¼šåªä¿å­˜è¶…éé–€æª»çš„é…å°
    results = {}
    total_matches = 0
    
    for momo_idx, momo_row in momo_products.iterrows():
        momo_id = str(momo_row['id'])
        similarities = similarity_matrix[momo_idx]
        
        # æ‰¾å‡ºè¶…éé–€æª»çš„ PChome å•†å“
        matches = []
        for pchome_idx, similarity in enumerate(similarities):
            if similarity >= threshold:
                pchome_row = pchome_products.iloc[pchome_idx]
                matches.append({
                    'pchome_id': str(pchome_row['id']),
                    'pchome_title': pchome_row['title'],
                    'pchome_price': float(pchome_row.get('price', 0)),
                    'pchome_image': pchome_row.get('image', ''),
                    'pchome_url': pchome_row.get('url', ''),
                    'pchome_sku': pchome_row.get('sku', ''),
                    'similarity': float(similarity)
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        matches = sorted(matches, key=lambda x: x['similarity'], reverse=True)
        
        if matches:
            results[momo_id] = matches
            total_matches += len(matches)
    
    print(f"  âœ… å®Œæˆï¼æ‰¾åˆ° {len(results)} å€‹ MOMO å•†å“æœ‰é…å°ï¼Œå…± {total_matches} çµ„é…å°")
    return results


def calculate_all_similarities(momo_csv='momo.csv', pchome_csv='pchome.csv', 
                               model_path=None, output_file='similarities.json',
                               threshold=0.739465):
    """
    è¨ˆç®—æ‰€æœ‰é¡åˆ¥çš„å•†å“ç›¸ä¼¼åº¦ä¸¦ä¿å­˜
    
    Args:
        momo_csv: MOMO å•†å“ CSV æª”æ¡ˆè·¯å¾‘
        pchome_csv: PChome å•†å“ CSV æª”æ¡ˆè·¯å¾‘
        model_path: æ¨¡å‹è·¯å¾‘
        output_file: è¼¸å‡ºçš„ JSON æª”æ¡ˆè·¯å¾‘
        threshold: ç›¸ä¼¼åº¦é–€æª»
    """
    print("=" * 60)
    print("ğŸš€ é–‹å§‹é å…ˆè¨ˆç®—å•†å“ç›¸ä¼¼åº¦...")
    print("=" * 60)
    
    # è¼‰å…¥è³‡æ–™
    print("\nğŸ“‚ è¼‰å…¥å•†å“è³‡æ–™...")
    try:
        # ç›´æ¥è®€å– CSVï¼Œä½¿ç”¨ç¬¬ä¸€è¡Œä½œç‚ºè¡¨é ­
        momo_df = pd.read_csv(momo_csv)
        pchome_df = pd.read_csv(pchome_csv)
        
        # ç¢ºä¿åƒ¹æ ¼æ˜¯æ•¸å€¼å‹
        momo_df['price'] = pd.to_numeric(momo_df['price'], errors='coerce')
        pchome_df['price'] = pd.to_numeric(pchome_df['price'], errors='coerce')
        
        print(f"  âœ… MOMO: {len(momo_df)} ä»¶å•†å“")
        print(f"  âœ… PChome: {len(pchome_df)} ä»¶å•†å“")
    except Exception as e:
        print(f"  âŒ è³‡æ–™è¼‰å…¥å¤±æ•—: {e}")
        return False
    
    # è¼‰å…¥æ¨¡å‹
    print("\nğŸ¤– è¼‰å…¥ SentenceTransformer æ¨¡å‹...")
    if model_path is None:
        model_path = os.path.join("models", "models20-multilingual-e5-large_fold_1")
    
    if not os.path.exists(model_path):
        print(f"  âŒ æ‰¾ä¸åˆ°æ¨¡å‹è·¯å¾‘: {model_path}")
        return False
    
    try:
        model = SentenceTransformer(model_path)
        print(f"  âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        print(f"  âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return False
    
    # è¨ˆç®—æ‰€æœ‰å•†å“çš„ç›¸ä¼¼åº¦ï¼ˆä¸åˆ†é¡åˆ¥ï¼‰
    print(f"\nğŸ“‹ é–‹å§‹è¨ˆç®—æ‰€æœ‰ MOMO èˆ‡ PChome å•†å“çš„é…å°")
    
    all_results = calculate_similarities_for_all(
        model, momo_df, pchome_df, threshold
    )
    
    # ä¿å­˜çµæœ
    print(f"\nğŸ’¾ ä¿å­˜ç›¸ä¼¼åº¦çµæœåˆ° {output_file}...")
    try:
        output_data = {
            'metadata': {
                'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'threshold': threshold,
                'total_momo_products': len(momo_df),
                'total_pchome_products': len(pchome_df),
                'total_matches': len(all_results),
                'momo_csv': momo_csv,
                'pchome_csv': pchome_csv
            },
            'similarities': all_results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"  âœ… æˆåŠŸä¿å­˜ï¼")
        print("\n" + "=" * 60)
        print("âœ¨ æ‰€æœ‰ç›¸ä¼¼åº¦è¨ˆç®—å®Œæˆï¼")
        print("=" * 60)
        return True
        
    except Exception as e:
        print(f"  âŒ ä¿å­˜å¤±æ•—: {e}")
        return False


if __name__ == "__main__":
    # å¯ä»¥ç›´æ¥åŸ·è¡Œæ­¤è…³æœ¬ä¾†è¨ˆç®—ç›¸ä¼¼åº¦
    calculate_all_similarities()
